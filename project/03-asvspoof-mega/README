General
----------
This project is detailed in this paper https://arxiv.org/abs/2103.11326.

Name of the model folder is FEAT-lcnn-NET-LOSS, where
 FEAT: lfb, lfcc, or spec2
 NET: fixed (fixed size input), lstm-sum, or attention
 LOSS: oc (one-class), am (additive margin), p2s (p2sgrad), sig (sigmoid)

Folder structure
----------------
|- 00_demo.sh: 
|   Demonstration script for model evaluation and training 
|   Pleae check document of this script for usage
|
|- 01_config.py: 
|   basic configuration for models (shared by all models)
|- 01_main.py:
|   basic main.py to train and evaluate model (shared by all models)
|- 02_evaluate.py:
|   script wrapper to compute EER and min tDCF
|
|- DATA/asvspoof2019_LA/
|  |- protocol.txt: 
|  |   concatenation of protocol files ASVspoof2019_LA_cm_protocols/*.txt. 
|  |   this will be loaded by pytorch code for training and evaluation
|  |- scp: 
|  |   list of files for traing, dev, and eval
|  |- train_dev: 
|  |   link to the folder that stores both train and dev waveform. 
|  |   both train and dev data are saved in the same folder. 
|  |- eval: 
|  |   link to the folder that stores test set waveforms
|
|- conv
|   Cached data on the trial length for specific databases
|   They are automatically produced by Pytorch code, given config.py
|   
|- 99_get.sh
|   script used by Xin to copy files


In each model folder, for example
|- lfcc-lcnn-lstmsum-p2s
|  |- 01: 
|  |  folder for the models in the 1st training-evaluation round
|  |  |- 00_train.sh: recipe to train the model
|  |  |- 01_eval.sh: command line to evaluate the model on eval set
|  |  |- model.py: definition of model in Pytorch code
|  |  |- __pretrained
|  |       |- trained_network.pt: pre-trained model 
|  |       |- log_output_testset: log that saves the score of eval trials
|  |
|  |- 02:
|     folder for the models in the 2nd training-evaluation round

The six folders share the same model definition (model.py). They are
just trained using different initial random seeds.


Usage
----------
1. Setup conda and Pytorch environment (see 4.Usage in ../../README.md)

2. Download [ASVspoof 2019 LA](https://doi.org/10.7488/ds/2555) 
   and convert FLAC to WAV

   Put eval set waves to ./DATA/asvspoof2019_LA/eval
   Put train and dev sets to ./DATA/asvspoof2019_LA/train_dev
   (You may also link eval and train_dev to the folder of waveforms)
   
   Make sure that the two folders contain the waveform files: 

   $: ls DATA/asvspoof2019_LA/eval 
   LA_E_1000147.wav
   LA_E_1000273.wav
   LA_E_1000791.wav
   LA_E_1000841.wav
   LA_E_1000989.wav
   ...
   $: ls DATA/asvspoof2019_LA/eval | wc -l
   71237

   $: ls DATA/asvspoof2019_LA/train_dev
   LA_D_1000265.wav
   LA_D_1000752.wav
   LA_D_1001095.wav
   LA_D_1002130.wav
   LA_D_1002200.wav
   LA_D_1002318.wav
   ...

   $: ls DATA/asvspoof2019_LA/train_dev | wc -l
   50224
   
   
   Since this commit, it is also OK to directly load *.flac.
   1. make sure you have installed soundfile (see ../../env.yml)
   2. put flac in DATA/asvspoof2019_LA/eval and DATA/asvspoof2019_LA/train_dev
   3. change in 01_config.py: input_exts = ['.wav'] to input_exts = ['.flac']
   That's all

4. Run this script 00_demo.sh
   For example, by
   $: bash 00_demo.sh lfcc-lcnn-lstmsum-p2s/01 > log_batch 2>$1 &

   This script will evaluate pre-trained models and train a new model
   It will take more than 10 hours to finish.

5. Try score fusing
   $: bash 00_demo_fuse_score.sh

   This script will fuse scores from pre-trained models, which 
   reproduce the result in a book chapter to be published.

   You can also try other scripts after modifying this simple script.

Note
----------

1. Running 00_demo.sh requires GPU card with sufficient memory
step2, model evaluation requires around 3GB GPU memory
step3, model training requires around 16GB GPU memory
If GPU memory is insufficient, please reduce --batch-size in */*/00_train.sh


2. The 00_demo.sh works in this way (for training or evaluation)
   1. go to a model folder
   2. 01_main.py and 01_config.py are copied to a model folder as main.py and config.py
   3. run python main.py with other options, 
      by default, it will load model.py in the model folder and config.py
   4. main.py asks core_scripts/data_io/default_data_io.py to scan the files and 
      prepare torch.utils.Dataset, given the information on the folder, file name extention
      and so on in config.py
   5. main.py load the model definition in model.py and call core_scripts/nn_manager to
      run the training or evaluation loop

3. Input data are provided as waveform, LFCC will be produced by the code internally.
   Target labels should be provided in protocol.txt (see DATA/asvspoof2019_la/protocol.txt)
  
   The model.py will parse protocol.txt and use the "bonafide" and "spoof" as target labels.

   The model.py will internally converts "bonafide" label to 1 and "spoof" label to 0
   Accordingly, the output score from the model looks like:

   Output, File name, label, score
   Output, LA_E_8688127, 0, -0.011127
   Output, LA_E_2504134, 1, 0.999660

   Where 0 and 1 denote spoof and bona fide, respectively.

4. model.py in this project was created from a common template.
   It has many functions unnecessary for ASVspoof model but required for the Pytorch scripts:
   model.prepare_mean_std, model.normalize_input, model.normalize_target, 
   model.denormalize_output.

   For ASVspoof models, we set input_norm = [False] in config.py, In this case, 
   mean = 0 and std = 1 are used for input data (i.e., waveform)
   
   After waveform is read, the front-end computes the acoustic features in each mini-batch.
   No normalization is conducted.
   
   ASVspoof models do not load target labels from disk. It gets the target label from file
   names and protocol (i.e., target_vec in model.py). Thus, model.normalize_target is not used
   on the target label. 
     
   model.forward() gives [scores, target_vec, True] to the script, and the script will 
   give [scores, target_vec, True] to Loss().compute() as the 1st non-self argument.
   Thus, in Loss().compute(outputs, target),
   outputs[0] denotes scores, and outputs[1] denotes target_vec.

   Note that target in Loss() is an empty list []. This argument "target" is for target data
   loaded from disk. But for ASVspoof models, the target labels are not loaded from disk, 
   thus target is []. This behavior is controled by output_dirs = [] in config.py. It tells
   The script not load anything as "target".
   
   
For a high-level explanation on how the functions and objects work in the script, please
check ../../README.md

If you want to use the code for other database, please check 04-asvspoof2021-baseline
and try the toy example. It will include a toy dataset for the training process

That's all

